{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jmXx-hS9ZMVj"
   },
   "source": [
    "# FSRS4Anki v4.10.2 Simulator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lurCmW0Jqz3s"
   },
   "source": [
    "[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/open-spaced-repetition/fsrs4anki/blob/v4.10.2/fsrs4anki_simulator.ipynb)\n",
    "\n",
    "â†‘ Click the above button to open the simulator on Google Colab.\n",
    "\n",
    "> If you can't see the button and are located in the Chinese Mainland, please use a proxy or VPN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BtW1uBOm6Djf"
   },
   "outputs": [],
   "source": [
    "# parameters for FSRS\n",
    "w = [1.1008, 1.2746, 5.7619, 10.5114, 5.3148, 1.5796, 1.244, 0.003, 1.5741, 0.1741, 1.0137, 2.7279, 0.0114, 0.3071, 0.3981, 0.0, 1.9569]\n",
    "requestRetention = 0.82  # recommended setting: 0.8 ~ 0.9\n",
    "\n",
    "# parameters for Anki\n",
    "graduatingInterval = 1\n",
    "easyInterval = 4\n",
    "easyBonus = 1.3\n",
    "hardInterval = 1.2\n",
    "intervalModifier = 1\n",
    "newInterval = 0\n",
    "minimumInterval = 1\n",
    "leechThreshold = 8\n",
    "leechSuspend = False\n",
    "\n",
    "# common parameters\n",
    "maximumInterval = 36500\n",
    "new_cards_limits = 20\n",
    "review_limits = 400\n",
    "max_time_limts = 10000\n",
    "learn_days = 300\n",
    "deck_size = 20000\n",
    "\n",
    "# get the true time from review logs\n",
    "filename = \"collection-2022-09-18@13-21-58.colpkg\"\n",
    "\n",
    "# smooth curves\n",
    "moving_average_period = 14\n",
    "\n",
    "# Set it to True if you don't want the optimizer to use the review logs from suspended cards.\n",
    "filter_out_suspended_cards = False\n",
    "\n",
    "# Red: 1, Orange: 2, Green: 3, Blue: 4, Pink: 5, Turquoise: 6, Purple: 7\n",
    "# Set it to [1, 2] if you don't want the optimizer to use the review logs from cards with red or orange flag.\n",
    "filter_out_flags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.14.0 requires torch==1.13.0, but you have torch 2.1.1 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\moses\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'collection-2022-09-18@13-21-58.colpkg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32madnansiddiquei\\AiTutor\\part_4\\fsrs4anki_simulator.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W3sdnNjb2RlLXZmcw%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfsrs_optimizer\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptimizer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W3sdnNjb2RlLXZmcw%3D%3D?line=11'>12</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mOptimizer()\n\u001b[1;32m---> <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W3sdnNjb2RlLXZmcw%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49manki_extract(filename, filter_out_suspended_cards, filter_out_flags)\n\u001b[0;32m     <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W3sdnNjb2RlLXZmcw%3D%3D?line=14'>15</a>\u001b[0m New \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W3sdnNjb2RlLXZmcw%3D%3D?line=15'>16</a>\u001b[0m Learning \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fsrs_optimizer\\fsrs_optimizer.py:418\u001b[0m, in \u001b[0;36mOptimizer.anki_extract\u001b[1;34m(self, filename, filter_out_suspended_cards, filter_out_flags)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m\"\"\"Step 1\"\"\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m# Extract the collection file or deck file to get the .anki21 database.\u001b[39;00m\n\u001b[1;32m--> 418\u001b[0m \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39;49mZipFile(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mfilename\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m zip_ref:\n\u001b[0;32m    419\u001b[0m     zip_ref\u001b[39m.\u001b[39mextractall(\u001b[39m\"\u001b[39m\u001b[39m./\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    420\u001b[0m     tqdm\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39mDeck file extracted successfully!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\zipfile.py:1249\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1248\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1249\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mopen(file, filemode)\n\u001b[0;32m   1250\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m   1251\u001b[0m         \u001b[39mif\u001b[39;00m filemode \u001b[39min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'collection-2022-09-18@13-21-58.colpkg'"
     ]
    }
   ],
   "source": [
    "%pip install -q fsrs_optimizer==4.18.2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# for local development\n",
    "# import os\n",
    "# import sys\n",
    "# sys.path.insert(0, os.path.abspath('../fsrs-optimizer/src/fsrs_optimizer/'))\n",
    "import fsrs_optimizer as optimizer\n",
    "\n",
    "optimizer = optimizer.Optimizer()\n",
    "optimizer.anki_extract(filename, filter_out_suspended_cards, filter_out_flags)\n",
    "\n",
    "New = 0\n",
    "Learning = 1\n",
    "Review = 2\n",
    "Relearning = 3\n",
    "\n",
    "df = pd.read_csv(\"sample_review_log.csv\")\n",
    "df.sort_values(by=[\"card_id\", \"review_time\"], inplace=True, ignore_index=True)\n",
    "\n",
    "new_card_revlog = df[\n",
    "    (df[\"review_state\"] == New) & (df[\"review_rating\"].isin([1, 2, 3, 4]))\n",
    "]\n",
    "first_rating_prob = np.zeros(4)\n",
    "first_rating_prob[new_card_revlog[\"review_rating\"].value_counts().index - 1] = (\n",
    "    new_card_revlog[\"review_rating\"].value_counts()\n",
    "    / new_card_revlog[\"review_rating\"].count()\n",
    ")\n",
    "recall_card_revlog = df[\n",
    "    (df[\"review_state\"] == Review) & (df[\"review_rating\"].isin([2, 3, 4]))\n",
    "]\n",
    "review_rating_prob = np.zeros(3)\n",
    "review_rating_prob[recall_card_revlog[\"review_rating\"].value_counts().index - 2] = (\n",
    "    recall_card_revlog[\"review_rating\"].value_counts()\n",
    "    / recall_card_revlog[\"review_rating\"].count()\n",
    ")\n",
    "\n",
    "df[\"review_state\"] = df[\"review_state\"].map(\n",
    "    lambda x: x if x != New else Learning)\n",
    "\n",
    "recall_costs = np.zeros(3)\n",
    "recall_costs_df = recall_card_revlog.groupby(by=\"review_rating\")[\n",
    "    \"review_duration\"\n",
    "].mean()\n",
    "recall_costs[recall_costs_df.index - 2] = recall_costs_df / 1000\n",
    "\n",
    "state_sequence = np.array(df[\"review_state\"])\n",
    "duration_sequence = np.array(df[\"review_duration\"])\n",
    "learn_cost = round(\n",
    "    df[df[\"review_state\"] == Learning][\"review_duration\"].sum()\n",
    "    / len(df[\"card_id\"].unique())\n",
    "    / 1000,\n",
    "    1,\n",
    ")\n",
    "\n",
    "state_block = dict()\n",
    "state_count = dict()\n",
    "state_duration = dict()\n",
    "last_state = state_sequence[0]\n",
    "state_block[last_state] = 1\n",
    "state_count[last_state] = 1\n",
    "state_duration[last_state] = duration_sequence[0]\n",
    "for i, state in enumerate(state_sequence[1:]):\n",
    "    state_count[state] = state_count.setdefault(state, 0) + 1\n",
    "    state_duration[state] = state_duration.setdefault(\n",
    "        state, 0) + duration_sequence[i]\n",
    "    if state != last_state:\n",
    "        state_block[state] = state_block.setdefault(state, 0) + 1\n",
    "    last_state = state\n",
    "\n",
    "recall_cost = round(state_duration[Review] / state_count[Review] / 1000, 1)\n",
    "\n",
    "if Relearning in state_count and Relearning in state_block:\n",
    "    forget_cost = round(\n",
    "        state_duration[Relearning] /\n",
    "        state_block[Relearning] / 1000 + recall_cost,\n",
    "        1,\n",
    "    )\n",
    "\n",
    "# print(f\"average time for failed reviews: {forget_cost}s\")\n",
    "# print(f\"average time for recalled reviews: {recall_cost}s\")\n",
    "# print(\n",
    "#     \"average time for `hard`, `good` and `easy` reviews: %.1fs, %.1fs, %.1fs\"\n",
    "#     % tuple(recall_costs)\n",
    "# )\n",
    "# print(f\"average time for learning a new card: {learn_cost}s\")\n",
    "# print(\n",
    "#     \"Ratio of `hard`, `good` and `easy` ratings for recalled reviews: %.2f, %.2f, %.2f\"\n",
    "#     % tuple(review_rating_prob)\n",
    "# )\n",
    "# print(\n",
    "#     \"Ratio of `again`, `hard`, `good` and `easy` ratings for new cards: %.2f, %.2f, %.2f, %.2f\"\n",
    "#     % tuple(first_rating_prob)\n",
    "# )\n",
    "\n",
    "\n",
    "def generate_rating(review_type):\n",
    "    if review_type == \"new\":\n",
    "        return np.random.choice([1, 2, 3, 4], p=first_rating_prob)\n",
    "    elif review_type == \"recall\":\n",
    "        return np.random.choice([2, 3, 4], p=review_rating_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'adnansiddiquei/AiTutor/part_4/flashcard_review_data.csvflashcard_review_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32madnansiddiquei\\AiTutor\\part_4\\fsrs4anki_simulator.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W6sdnNjb2RlLXZmcw%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W6sdnNjb2RlLXZmcw%3D%3D?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39madnansiddiquei/AiTutor/part_4/flashcard_review_data.csvflashcard_review_data.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W6sdnNjb2RlLXZmcw%3D%3D?line=3'>4</a>\u001b[0m df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcard_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreview_time\u001b[39m\u001b[39m\"\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W6sdnNjb2RlLXZmcw%3D%3D?line=4'>5</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'adnansiddiquei/AiTutor/part_4/flashcard_review_data.csvflashcard_review_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"adnansiddiquei/AiTutor/part_4/flashcard_review_data.csvflashcard_review_data.csv\")\n",
    "df.sort_values(by=[\"card_id\", \"review_time\"], inplace=True, ignore_index=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'learn_cost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32madnansiddiquei\\AiTutor\\part_4\\fsrs4anki_simulator.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=234'>235</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=235'>236</a>\u001b[0m learned \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=236'>237</a>\u001b[0m learn_time_today \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m learn_cost\n\u001b[0;32m    <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=237'>238</a>\u001b[0m card\u001b[39m.\u001b[39miat[idx, field_map[\u001b[39m\"\u001b[39m\u001b[39mlast_date\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m=\u001b[39m day\n\u001b[0;32m    <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=239'>240</a>\u001b[0m card\u001b[39m.\u001b[39miat[idx, field_map[\u001b[39m\"\u001b[39m\u001b[39mreps\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'learn_cost' is not defined"
     ]
    }
   ],
   "source": [
    "from fsrs_optimizer import lineToTensor, FSRS\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Collection:\n",
    "    def __init__(self):\n",
    "        self.model = FSRS(w)\n",
    "        self.model.eval()\n",
    "\n",
    "    def states(self, t_history, r_history):\n",
    "        with torch.no_grad():\n",
    "            line_tensor = lineToTensor(\n",
    "                list(zip([str(t_history)], [str(r_history)]))[0]\n",
    "            ).unsqueeze(1)\n",
    "            output_t = self.model(line_tensor)\n",
    "            return output_t[-1][0]\n",
    "\n",
    "    def next_states(self, states, t, r):\n",
    "        with torch.no_grad():\n",
    "            return self.model.step(torch.FloatTensor([[t, r]]), states.unsqueeze(0))[0]\n",
    "\n",
    "    def init(self):\n",
    "        t = 0\n",
    "        r = generate_rating(\"new\")\n",
    "        p = round(first_rating_prob[r - 1], 2)\n",
    "        new_states = self.states(t, r)\n",
    "        return r, t, p, new_states\n",
    "\n",
    "\n",
    "feature_list = [\n",
    "    \"difficulty\",\n",
    "    \"stability\",\n",
    "    \"retrievability\",\n",
    "    \"delta_t\",\n",
    "    \"reps\",\n",
    "    \"lapses\",\n",
    "    \"last_date\",\n",
    "    \"due\",\n",
    "    \"r_history\",\n",
    "    \"t_history\",\n",
    "    \"p_history\",\n",
    "    \"states\",\n",
    "    \"time\",\n",
    "    \"factor\",\n",
    "]\n",
    "field_map = {key: i for i, key in enumerate(feature_list)}\n",
    "\n",
    "\n",
    "def fsrs4anki_scheduler(stability):\n",
    "    def constrain_interval(stability):\n",
    "        if stability > 0:\n",
    "            return min(\n",
    "                max(1, round(9 * stability * (1 / requestRetention - 1))),\n",
    "                maximumInterval,\n",
    "            )\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    interval = constrain_interval(stability)\n",
    "    return interval\n",
    "\n",
    "\n",
    "def anki_scheduler(interval, real_interval, factor, rating):\n",
    "    if factor is None:\n",
    "        return (graduatingInterval, 2.5) if rating != 4 else (easyInterval, 2.5)\n",
    "    delay = real_interval - interval\n",
    "    again_interval = min(\n",
    "        max(round(interval * newInterval * intervalModifier + 0.01), minimumInterval),\n",
    "        maximumInterval,\n",
    "    )\n",
    "    hard_interval = min(\n",
    "        max(\n",
    "            round(interval * hardInterval * intervalModifier + 0.01),\n",
    "            interval + 1,\n",
    "            minimumInterval,\n",
    "        ),\n",
    "        maximumInterval,\n",
    "    )\n",
    "    good_interval = min(\n",
    "        max(\n",
    "            round((interval + delay / 2) * factor * intervalModifier + 0.01),\n",
    "            hard_interval + 1,\n",
    "            minimumInterval,\n",
    "        ),\n",
    "        maximumInterval,\n",
    "    )\n",
    "    easy_interval = min(\n",
    "        max(\n",
    "            round(real_interval * factor * intervalModifier * easyBonus + 0.01),\n",
    "            good_interval + 1,\n",
    "            minimumInterval,\n",
    "        ),\n",
    "        maximumInterval,\n",
    "    )\n",
    "    if rating == 1:\n",
    "        return again_interval, max(factor - 0.2, 1.3)\n",
    "    if rating == 2:\n",
    "        return hard_interval, max(factor - 0.15, 1.3)\n",
    "    if rating == 3:\n",
    "        return good_interval, max(factor, 1.3)\n",
    "    if rating == 4:\n",
    "        return easy_interval, max(factor + 0.15, 1.3)\n",
    "    return maximumInterval, factor\n",
    "\n",
    "\n",
    "def scheduler(scheduler_name, fsrs_inputs, anki_inputs):\n",
    "    if scheduler_name == \"anki\":\n",
    "        return anki_scheduler(*anki_inputs)\n",
    "    elif scheduler_name == \"fsrs\":\n",
    "        return fsrs4anki_scheduler(fsrs_inputs), 2.5\n",
    "    return None\n",
    "\n",
    "\n",
    "for scheduler_name in (\"anki\", \"fsrs\"):\n",
    "    new_card_per_day = np.array([0] * learn_days)\n",
    "    new_card_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "    review_card_per_day = np.array([0.0] * learn_days)\n",
    "    review_card_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "    time_per_day = np.array([0.0] * learn_days)\n",
    "    time_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "    learned_per_day = np.array([0.0] * learn_days)\n",
    "    retention_per_day = np.array([0.0] * learn_days)\n",
    "    expected_memorization_per_day = np.array([0.0] * learn_days)\n",
    "\n",
    "    card = pd.DataFrame(\n",
    "        np.zeros((deck_size, len(feature_list))),\n",
    "        index=range(deck_size),\n",
    "        columns=feature_list,\n",
    "    )\n",
    "    card[\"states\"] = card[\"states\"].astype(object)\n",
    "    card[\"reps\"] = 0\n",
    "    card[\"lapses\"] = 0\n",
    "    card[\"due\"] = learn_days\n",
    "\n",
    "    student = Collection()\n",
    "    random.seed(2022)\n",
    "    for day in tqdm(range(learn_days)):\n",
    "        reviewed = 0\n",
    "        learned = 0\n",
    "        review_time_today = 0\n",
    "        learn_time_today = 0\n",
    "\n",
    "        card[\"delta_t\"] = day - card[\"last_date\"]\n",
    "        card[\"retrievability\"] = np.power(\n",
    "            1 + card[\"delta_t\"] / (9 * card[\"stability\"]), -1\n",
    "        )\n",
    "        need_review = (\n",
    "            card[card[\"due\"] <= day]\n",
    "            if leechSuspend == False\n",
    "            else card[(card[\"due\"] <= day) & (card[\"lapses\"] < leechThreshold)]\n",
    "        )\n",
    "        retention_per_day[day] = need_review[\"retrievability\"].mean()\n",
    "        for idx in need_review.index:\n",
    "            if (\n",
    "                reviewed >= review_limits\n",
    "                or review_time_today + learn_time_today >= max_time_limts\n",
    "            ):\n",
    "                break\n",
    "\n",
    "            reviewed += 1\n",
    "            last_date = card.iat[idx, field_map[\"last_date\"]]\n",
    "            due = card.iat[idx, field_map[\"due\"]]\n",
    "            factor = card.iat[idx, field_map[\"factor\"]]\n",
    "            card.iat[idx, field_map[\"last_date\"]] = day\n",
    "            ivl = card.iat[idx, field_map[\"delta_t\"]]\n",
    "            card.iat[idx, field_map[\"t_history\"]] += f\",{ivl}\"\n",
    "\n",
    "            stability = card.iat[idx, field_map[\"stability\"]]\n",
    "            retrievability = card.iat[idx, field_map[\"retrievability\"]]\n",
    "            card.iat[idx, field_map[\"p_history\"]] += f\",{retrievability:.2f}\"\n",
    "            reps = card.iat[idx, field_map[\"reps\"]]\n",
    "            lapses = card.iat[idx, field_map[\"lapses\"]]\n",
    "            states = card.iat[idx, field_map[\"states\"]]\n",
    "\n",
    "            if random.random() < retrievability:\n",
    "                rating = generate_rating(\"recall\")\n",
    "                recall_time = recall_costs[rating - 2]\n",
    "                review_time_today += recall_time\n",
    "                card.iat[idx, field_map[\"r_history\"]] += f\",{rating}\"\n",
    "                new_states = student.next_states(states, ivl, rating)\n",
    "                new_stability = float(new_states[0])\n",
    "                new_difficulty = float(new_states[1])\n",
    "                card.iat[idx, field_map[\"stability\"]] = new_stability\n",
    "                card.iat[idx, field_map[\"difficulty\"]] = new_difficulty\n",
    "                card.iat[idx, field_map[\"states\"]] = new_states\n",
    "                card.iat[idx, field_map[\"reps\"]] = reps + 1\n",
    "                card.iat[idx, field_map[\"time\"]] += recall_time\n",
    "\n",
    "                delta_t, factor = scheduler(\n",
    "                    scheduler_name,\n",
    "                    new_stability,\n",
    "                    (due - last_date, ivl, factor, rating),\n",
    "                )\n",
    "                card.iat[idx, field_map[\"factor\"]] = factor\n",
    "                card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "\n",
    "            else:\n",
    "                review_time_today += forget_cost\n",
    "\n",
    "                rating = 1\n",
    "                card.iat[idx, field_map[\"r_history\"]] += f\",{rating}\"\n",
    "\n",
    "                new_states = student.next_states(states, ivl, 1)\n",
    "                new_stability = float(new_states[0])\n",
    "                new_difficulty = float(new_states[1])\n",
    "\n",
    "                card.iat[idx, field_map[\"stability\"]] = new_stability\n",
    "                card.iat[idx, field_map[\"difficulty\"]] = new_difficulty\n",
    "                card.iat[idx, field_map[\"states\"]] = new_states\n",
    "\n",
    "                reps = 0\n",
    "                lapses = lapses + 1\n",
    "\n",
    "                card.iat[idx, field_map[\"reps\"]] = reps\n",
    "                card.iat[idx, field_map[\"lapses\"]] = lapses\n",
    "\n",
    "                delta_t, factor = scheduler(\n",
    "                    scheduler_name,\n",
    "                    new_stability,\n",
    "                    (due - last_date, ivl, factor, rating),\n",
    "                )\n",
    "                card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "                card.iat[idx, field_map[\"factor\"]] = factor\n",
    "                card.iat[idx, field_map[\"time\"]] += forget_cost\n",
    "\n",
    "        need_learn = card[card[\"stability\"] == 0]\n",
    "\n",
    "        for idx in need_learn.index:\n",
    "            if (\n",
    "                learned >= new_cards_limits\n",
    "                or review_time_today + learn_time_today >= max_time_limts\n",
    "            ):\n",
    "                break\n",
    "            learned += 1\n",
    "            learn_time_today += learn_cost\n",
    "            card.iat[idx, field_map[\"last_date\"]] = day\n",
    "\n",
    "            card.iat[idx, field_map[\"reps\"]] = 1\n",
    "            card.iat[idx, field_map[\"lapses\"]] = 0\n",
    "\n",
    "            r, t, p, new_states = student.init()\n",
    "            new_stability = float(new_states[0])\n",
    "            new_difficulty = float(new_states[1])\n",
    "\n",
    "            card.iat[idx, field_map[\"r_history\"]] = str(r)\n",
    "            card.iat[idx, field_map[\"t_history\"]] = str(t)\n",
    "            card.iat[idx, field_map[\"p_history\"]] = str(p)\n",
    "            card.iat[idx, field_map[\"stability\"]] = new_stability\n",
    "            card.iat[idx, field_map[\"difficulty\"]] = new_difficulty\n",
    "            card.iat[idx, field_map[\"states\"]] = new_states\n",
    "\n",
    "            delta_t, factor = scheduler(\n",
    "                scheduler_name, new_stability, (None, None, None, r)\n",
    "            )\n",
    "            card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "            card.iat[idx, field_map[\"time\"]] = learn_cost\n",
    "            card.iat[idx, field_map[\"factor\"]] = factor\n",
    "\n",
    "        new_card_per_day[day] = learned\n",
    "        review_card_per_day[day] = reviewed\n",
    "        learned_per_day[day] = learned_per_day[day - 1] + learned\n",
    "        time_per_day[day] = review_time_today + learn_time_today\n",
    "        expected_memorization_per_day[day] = sum(\n",
    "            card[card[\"retrievability\"] > 0][\"retrievability\"]\n",
    "        )\n",
    "\n",
    "        if day >= moving_average_period:\n",
    "            new_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                new_card_per_day[day - moving_average_period: day].sum(),\n",
    "                moving_average_period,\n",
    "            )\n",
    "            review_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                review_card_per_day[day - moving_average_period: day].sum(),\n",
    "                moving_average_period,\n",
    "            )\n",
    "            time_per_day_average_per_period[day] = np.true_divide(\n",
    "                time_per_day[day - moving_average_period: day].sum(),\n",
    "                moving_average_period,\n",
    "            )\n",
    "        else:\n",
    "            new_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                new_card_per_day[: day + 1].sum(), day + 1\n",
    "            )\n",
    "            review_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                review_card_per_day[: day + 1].sum(), day + 1\n",
    "            )\n",
    "            time_per_day_average_per_period[day] = np.true_divide(\n",
    "                time_per_day[: day + 1].sum(), day + 1\n",
    "            )\n",
    "\n",
    "    total_learned = sum(new_card_per_day)\n",
    "    total_time = sum(time_per_day)\n",
    "    total_remembered = int(card[\"retrievability\"].sum())\n",
    "    total_leeches = len(card[card[\"lapses\"] >= leechThreshold])\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(review_card_per_day_average_per_period, label=f\"{scheduler_name}\")\n",
    "    plt.figure(2)\n",
    "    plt.plot(time_per_day_average_per_period / 60, label=f\"{scheduler_name}\")\n",
    "    plt.figure(3)\n",
    "    plt.plot(learned_per_day, label=f\"{scheduler_name}\")\n",
    "    plt.figure(4)\n",
    "    plt.plot(retention_per_day, label=f\"{scheduler_name}\")\n",
    "    plt.figure(5)\n",
    "    plt.plot(expected_memorization_per_day, label=f\"{scheduler_name}\")\n",
    "\n",
    "    print(\"scheduler:\", scheduler_name)\n",
    "    print(\"learned cards:\", total_learned)\n",
    "    print(\"time in minutes:\", round(total_time / 60, 1))\n",
    "    print(\"remembered cards:\", total_remembered)\n",
    "    print(\"time per remembered card:\", round(\n",
    "        total_time / 60 / total_remembered, 2))\n",
    "    print(\"leeches:\", total_leeches)\n",
    "\n",
    "    save = card[card[\"retrievability\"] > 0].copy()\n",
    "    save[\"stability\"] = round(save[\"stability\"], 2)\n",
    "    save[\"retrievability\"] = round(save[\"retrievability\"], 2)\n",
    "    save[\"difficulty\"] = round(save[\"difficulty\"], 2)\n",
    "    save[\"factor\"] = round(save[\"factor\"], 2)\n",
    "    save[\"time\"] = round(save[\"time\"], 2)\n",
    "\n",
    "    save.to_csv(f\"./simulator-{scheduler_name}.tsv\", index=False, sep=\"\\t\")\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title(f\"new cards limits:{new_cards_limits}-learn days:{learn_days}\")\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(f\"review cards per day ({moving_average_period} days average)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.figure(2)\n",
    "plt.title(f\"new cards limits:{new_cards_limits}-learn days:{learn_days}\")\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(f\"time in minutes per day ({moving_average_period} days average)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.figure(3)\n",
    "plt.title(f\"new cards limits:{new_cards_limits}-learn days:{learn_days}\")\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(f\"cards total learned\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.figure(4)\n",
    "plt.title(f\"new cards limits:{new_cards_limits}-learn days:{learn_days}\")\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(\"retention per day\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.figure(5)\n",
    "plt.title(f\"new cards limits:{new_cards_limits}-learn days:{learn_days}\")\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(\"expected memorization per day\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'card' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32madnansiddiquei\\AiTutor\\part_4\\fsrs4anki_simulator.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell://github/adnansiddiquei/AiTutor/part_4/fsrs4anki_simulator.ipynb#W5sdnNjb2RlLXZmcw%3D%3D?line=0'>1</a>\u001b[0m card\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'card' is not defined"
     ]
    }
   ],
   "source": [
    "card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOm4HfyD2iOIc2PUtxA92by",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8dd9a290ffd10997e0b0d411ff1325a47862ea932e0fd309ade800e0e51d2b4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
