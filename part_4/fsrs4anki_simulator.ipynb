{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jmXx-hS9ZMVj"
   },
   "source": [
    "# FSRS4Anki Scheduler Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "BtW1uBOm6Djf"
   },
   "outputs": [],
   "source": [
    "# Necessary Input:\n",
    "# z_score - only for questions that have been asked\n",
    "# asked questions to put into scheduler\n",
    "\n",
    "# parameters for FSRS\n",
    "w = [1.1008, 1.2746, 5.7619, 10.5114, 5.3148, 1.5796, 1.244, 0.003, 1.5741, 0.1741, 1.0137, 2.7279, 0.0114, 0.3071, 0.3981, 0.0, 1.9569]\n",
    "requestRetention = 0.82  # recommended setting: 0.8 ~ 0.9\n",
    "\n",
    "# parameters for Anki\n",
    "graduatingInterval = 1\n",
    "easyInterval = 4\n",
    "easyBonus = 1.3\n",
    "hardInterval = 1.2\n",
    "intervalModifier = 1\n",
    "newInterval = 0\n",
    "minimumInterval = 1\n",
    "leechThreshold = 8\n",
    "leechSuspend = False\n",
    "\n",
    "# common parameters\n",
    "maximumInterval = 36500\n",
    "new_cards_limits = 20\n",
    "review_limits = 400\n",
    "max_time_limts = 10000\n",
    "learn_days = 50\n",
    "\n",
    "# How many questions have we asked?\n",
    "deck_size = 1000\n",
    "\n",
    "# get the true time from review logs\n",
    "filename = \"collection-2022-09-18@13-21-58.colpkg\"\n",
    "\n",
    "# smooth curves\n",
    "moving_average_period = 14\n",
    "\n",
    "# Set it to True if you don't want the optimizer to use the review logs from suspended cards.\n",
    "filter_out_suspended_cards = False\n",
    "\n",
    "# Red: 1, Orange: 2, Green: 3, Blue: 4, Pink: 5, Turquoise: 6, Purple: 7\n",
    "# Set it to [1, 2] if you don't want the optimizer to use the review logs from cards with red or orange flag.\n",
    "filter_out_flags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle(\"sample_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_state</th>\n",
       "      <th>z_scores</th>\n",
       "      <th>review_duration</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_time_curr</th>\n",
       "      <th>review_state_curr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 5, 10, 15]</td>\n",
       "      <td>[0, 1, 1, 1]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>[3, 2, 1]</td>\n",
       "      <td>0.300</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.500</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[3, 7]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.700</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[2, 6, 10, 14]</td>\n",
       "      <td>[1, 2, 3, 2]</td>\n",
       "      <td>0.900</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     review_time  review_state  z_scores  review_duration  review_rating  \\\n",
       "0   1  [1, 5, 10, 15]  [0, 1, 1, 1]     0.001                5              1   \n",
       "1   2    [20, 25, 30]     [3, 2, 1]     0.300                5              2   \n",
       "2   3             [5]           [2]     0.500                5              3   \n",
       "3   4          [3, 7]        [0, 1]     0.700                5              3   \n",
       "4   5  [2, 6, 10, 14]  [1, 2, 3, 2]     0.900                4              4   \n",
       "\n",
       "   review_time_curr  review_state_curr  \n",
       "0                15                  1  \n",
       "1                30                  1  \n",
       "2                 5                  2  \n",
       "3                 7                  1  \n",
       "4                14                  2  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"data.csv\", columns = [\"id, review_time, review_state, z_scores\"])\n",
    "data = {\n",
    "    \"id\": [1, 2, 3, 4, 5],\n",
    "    \"review_time\": [[1, 5, 10, 15], [20, 25, 30], [5], [3, 7], [2, 6, 10, 14]],\n",
    "    \"review_state\": [[0, 1, 1, 1], [3, 2, 1], [2], [0, 1], [1, 2, 3, 2]],\n",
    "    \"z_scores\": [0.001, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "deck_size = len(df)\n",
    "\n",
    "def calculate_review_duration(states, times):\n",
    "    if states[-1] != 2:\n",
    "        return 5\n",
    "    else:\n",
    "        # Find the most recent transition to state 2 from either 1 or 3\n",
    "        for i in range(len(states) - 1, 0, -1):\n",
    "            if states[i] == 2 and (states[i - 1] == 1 or states[i - 1] == 3):\n",
    "                return times[i] - times[i - 1]\n",
    "        return 5  # Default value if no valid transition is found\n",
    "\n",
    "# Apply the function to each row\n",
    "df['review_duration'] = [calculate_review_duration(s, t) for s, t in zip(df['review_state'], df['review_time'])]\n",
    "\n",
    "# Define the bins for the intervals\n",
    "bins = [0.25, 0.5, 0.75]\n",
    "\n",
    "# Use numpy's digitize method to convert z_scores to review_rating\n",
    "df['review_rating'] = np.digitize(df['z_scores'], bins) + 1\n",
    "df['review_time_curr'] = df['review_time'].apply(lambda x: x[-1])\n",
    "df['review_state_curr'] = df['review_state'].apply(lambda x: x[-1])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average time for failed reviews: 0.0s\n",
      "average time for recalled reviews: 0.0s\n",
      "average time for `hard`, `good` and `easy` reviews: 0.0s, 0.0s, 0.0s\n",
      "average time for learning a new card: 0.0s\n",
      "Ratio of `hard`, `good` and `easy` ratings for recalled reviews: 0.00, 0.50, 0.50\n",
      "Ratio of `again`, `hard`, `good` and `easy` ratings for new cards: 0.25, 0.36, 0.06, 0.32\n"
     ]
    }
   ],
   "source": [
    "New = 0\n",
    "Learning = 1\n",
    "Review = 2\n",
    "Relearning = 3\n",
    "\n",
    "df.sort_values(by=[\"id\", \"review_time_curr\"], inplace=True, ignore_index=True)\n",
    "\n",
    "# new_card_revlog = df[\n",
    "#     (df[\"review_state_curr\"] == New) & (df[\"review_rating\"].isin([1, 2, 3, 4]))\n",
    "# ]\n",
    "# first_rating_prob = np.zeros(4)\n",
    "# first_rating_prob[new_card_revlog[\"review_rating\"].value_counts().index - 1] = (\n",
    "#     new_card_revlog[\"review_rating\"].value_counts()\n",
    "#     / new_card_revlog[\"review_rating\"].count()\n",
    "# )\n",
    "# print(first_rating_prob)\n",
    "recall_card_revlog = df[\n",
    "    (df[\"review_state_curr\"] == Review) & (df[\"review_rating\"].isin([2, 3, 4]))\n",
    "]\n",
    "review_rating_prob = np.zeros(3)\n",
    "review_rating_prob[recall_card_revlog[\"review_rating\"].value_counts().index - 2] = (\n",
    "    recall_card_revlog[\"review_rating\"].value_counts()\n",
    "    / recall_card_revlog[\"review_rating\"].count()\n",
    ")\n",
    "random_array = np.random.rand(4)\n",
    "random_array /= random_array.sum()\n",
    "first_rating_prob = random_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df[\"review_state_curr\"] = df[\"review_state_curr\"].map(\n",
    "    lambda x: x if x != New else Learning)\n",
    "\n",
    "recall_costs = np.zeros(3)\n",
    "recall_costs_df = recall_card_revlog.groupby(by=\"review_rating\")[\n",
    "    \"review_duration\"\n",
    "].mean()\n",
    "recall_costs[recall_costs_df.index - 2] = recall_costs_df / 1000\n",
    "\n",
    "state_sequence = np.array(df[\"review_state_curr\"])\n",
    "duration_sequence = np.array(df[\"review_duration\"])\n",
    "learn_cost = round(\n",
    "    df[df[\"review_state_curr\"] == Learning][\"review_duration\"].sum()\n",
    "    / len(df[\"id\"].unique())\n",
    "    / 1000,\n",
    "    1,\n",
    ")\n",
    "\n",
    "state_block = dict()\n",
    "state_count = dict()\n",
    "state_duration = dict()\n",
    "last_state = state_sequence[0]\n",
    "state_block[last_state] = 1\n",
    "state_count[last_state] = 1\n",
    "state_duration[last_state] = duration_sequence[0]\n",
    "for i, state in enumerate(state_sequence[1:]):\n",
    "    state_count[state] = state_count.setdefault(state, 0) + 1\n",
    "    state_duration[state] = state_duration.setdefault(\n",
    "        state, 0) + duration_sequence[i]\n",
    "    if state != last_state:\n",
    "        state_block[state] = state_block.setdefault(state, 0) + 1\n",
    "    last_state = state\n",
    "\n",
    "recall_cost = round(state_duration[Review] / state_count[Review] / 1000, 1)\n",
    "\n",
    "if Relearning in state_count and Relearning in state_block:\n",
    "    forget_cost = round(\n",
    "        state_duration[Relearning] /\n",
    "        state_block[Relearning] / 1000 + recall_cost,\n",
    "        1,\n",
    "    )\n",
    "\n",
    "print(f\"average time for failed reviews: {forget_cost}s\")\n",
    "print(f\"average time for recalled reviews: {recall_cost}s\")\n",
    "print(\n",
    "    \"average time for `hard`, `good` and `easy` reviews: %.1fs, %.1fs, %.1fs\"\n",
    "    % tuple(recall_costs)\n",
    ")\n",
    "print(f\"average time for learning a new card: {learn_cost}s\")\n",
    "print(\n",
    "    \"Ratio of `hard`, `good` and `easy` ratings for recalled reviews: %.2f, %.2f, %.2f\"\n",
    "    % tuple(review_rating_prob)\n",
    ")\n",
    "print(\n",
    "    \"Ratio of `again`, `hard`, `good` and `easy` ratings for new cards: %.2f, %.2f, %.2f, %.2f\"\n",
    "    % tuple(first_rating_prob)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_state</th>\n",
       "      <th>z_scores</th>\n",
       "      <th>review_duration</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_time_curr</th>\n",
       "      <th>review_state_curr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 5, 10, 15]</td>\n",
       "      <td>[0, 1, 1, 1]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>[3, 2, 1]</td>\n",
       "      <td>0.300</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.500</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[3, 7]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.700</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[2, 6, 10, 14]</td>\n",
       "      <td>[1, 2, 3, 2]</td>\n",
       "      <td>0.900</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     review_time  review_state  z_scores  review_duration  review_rating  \\\n",
       "0   1  [1, 5, 10, 15]  [0, 1, 1, 1]     0.001                5              1   \n",
       "1   2    [20, 25, 30]     [3, 2, 1]     0.300                5              2   \n",
       "2   3             [5]           [2]     0.500                5              3   \n",
       "3   4          [3, 7]        [0, 1]     0.700                5              3   \n",
       "4   5  [2, 6, 10, 14]  [1, 2, 3, 2]     0.900                4              4   \n",
       "\n",
       "   review_time_curr  review_state_curr  \n",
       "0                15                  1  \n",
       "1                30                  1  \n",
       "2                 5                  2  \n",
       "3                 7                  1  \n",
       "4                14                  2  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsrs_optimizer import lineToTensor, FSRS\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "date = 30\n",
    "\n",
    "def generate_rating(review_type):\n",
    "    if review_type == \"new\":\n",
    "        return np.random.choice([1, 2, 3, 4], p=first_rating_prob)\n",
    "    elif review_type == \"recall\":\n",
    "        return np.random.choice([2, 3, 4], p=review_rating_prob)\n",
    "\n",
    "class Collection:\n",
    "    def __init__(self):\n",
    "        self.model = FSRS(w)\n",
    "        self.model.eval()\n",
    "\n",
    "    def states(self, t_history, r_history):\n",
    "        with torch.no_grad():\n",
    "            line_tensor = lineToTensor(\n",
    "                list(zip([str(t_history)], [str(r_history)]))[0]\n",
    "            ).unsqueeze(1)\n",
    "            output_t = self.model(line_tensor)\n",
    "            return output_t[-1][0]\n",
    "\n",
    "    def next_states(self, states, t, r):\n",
    "        with torch.no_grad():\n",
    "            return self.model.step(torch.FloatTensor([[t, r]]), states.unsqueeze(0))[0]\n",
    "\n",
    "    def init(self):\n",
    "        t = date-1\n",
    "        r = generate_rating(\"new\")\n",
    "        p = round(first_rating_prob[r - 1], 2)\n",
    "        new_states = self.states(t, r)\n",
    "        return r, t, p, new_states\n",
    "\n",
    "\n",
    "feature_list = [\n",
    "    \"id\",\n",
    "    \"difficulty\",\n",
    "    \"stability\",\n",
    "    \"retrievability\",\n",
    "    \"delta_t\",\n",
    "    \"reps\",\n",
    "    \"lapses\",\n",
    "    \"last_date\",\n",
    "    \"due\",\n",
    "    \"r_history\",\n",
    "    \"t_history\",\n",
    "    \"p_history\",\n",
    "    \"states\",\n",
    "    \"time\",\n",
    "    \"factor\",\n",
    "]\n",
    "field_map = {key: i for i, key in enumerate(feature_list)}\n",
    "\n",
    "\n",
    "def fsrs4anki_scheduler(stability):\n",
    "    def constrain_interval(stability):\n",
    "        if stability > 0:\n",
    "            return min(\n",
    "                max(1, round(9 * stability * (1 / requestRetention - 1))),\n",
    "                maximumInterval,\n",
    "            )\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    interval = constrain_interval(stability)\n",
    "    return interval\n",
    "\n",
    "\n",
    "def scheduler(fsrs_inputs):\n",
    "        return fsrs4anki_scheduler(fsrs_inputs), 2.5\n",
    "\n",
    "#for scheduler_name in (\"anki\", \"fsrs\"):\n",
    "for scheduler_name in [\"fsrs\"]:\n",
    "    new_card_per_day = np.array([0] * learn_days)\n",
    "    new_card_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "    review_card_per_day = np.array([0.0] * learn_days)\n",
    "    review_card_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "    time_per_day = np.array([0.0] * learn_days)\n",
    "    time_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "    learned_per_day = np.array([0.0] * learn_days)\n",
    "    retention_per_day = np.array([0.0] * learn_days)\n",
    "    expected_memorization_per_day = np.array([0.0] * learn_days)\n",
    "\n",
    "    card = pd.DataFrame(\n",
    "        np.zeros((deck_size, len(feature_list))),\n",
    "        index=range(deck_size),\n",
    "        columns=feature_list,\n",
    "    )\n",
    "    card[\"id\"] = df[\"id\"]\n",
    "    card[\"states\"] = card[\"states\"].astype(object)\n",
    "    card['reps'] = df['review_state'].apply(lambda x: len(x))\n",
    "    card[\"lapses\"] = 0\n",
    "    card[\"due\"] = learn_days\n",
    "    card[\"last_date\"] = df[\"review_time\"].apply(lambda x: x[-1])\n",
    "    \n",
    "    student = Collection()\n",
    "    random.seed(2022)\n",
    "    # do 1 step:\n",
    "    day = date\n",
    "    reviewed = 0\n",
    "    learned = 0\n",
    "    review_time_today = 0\n",
    "    learn_time_today = 0\n",
    "\n",
    "    card[\"delta_t\"] = day - card[\"last_date\"]\n",
    "    card[\"retrievability\"] = np.power(\n",
    "        1 + card[\"delta_t\"] / (9 * card[\"stability\"]), -1\n",
    "    )\n",
    "    need_review = (\n",
    "        card[card[\"due\"] <= day]\n",
    "        if leechSuspend == False\n",
    "        else card[(card[\"due\"] <= day) & (card[\"lapses\"] < leechThreshold)]\n",
    "    )\n",
    "    retention_per_day[day] = need_review[\"retrievability\"].mean()\n",
    "    for idx in need_review.index:\n",
    "        if (\n",
    "            reviewed >= review_limits\n",
    "            or review_time_today + learn_time_today >= max_time_limts\n",
    "        ):\n",
    "            break\n",
    "\n",
    "        reviewed += 1\n",
    "        last_date = card.iat[idx, field_map[\"last_date\"]]\n",
    "        due = card.iat[idx, field_map[\"due\"]]\n",
    "        factor = card.iat[idx, field_map[\"factor\"]]\n",
    "        card.iat[idx, field_map[\"last_date\"]] = day\n",
    "        ivl = card.iat[idx, field_map[\"delta_t\"]]\n",
    "        card.iat[idx, field_map[\"t_history\"]] += f\",{ivl}\"\n",
    "\n",
    "        stability = card.iat[idx, field_map[\"stability\"]]\n",
    "        retrievability = card.iat[idx, field_map[\"retrievability\"]]\n",
    "        card.iat[idx, field_map[\"p_history\"]] += f\",{retrievability:.2f}\"\n",
    "        reps = card.iat[idx, field_map[\"reps\"]]\n",
    "        lapses = card.iat[idx, field_map[\"lapses\"]]\n",
    "        states = card.iat[idx, field_map[\"states\"]]\n",
    "\n",
    "        if random.random() < retrievability:\n",
    "            rating = generate_rating(\"recall\")\n",
    "            recall_time = recall_costs[rating - 2]\n",
    "            review_time_today += recall_time\n",
    "            card.iat[idx, field_map[\"r_history\"]] += f\",{rating}\"\n",
    "            new_states = student.next_states(states, ivl, rating)\n",
    "            new_stability = float(new_states[0])\n",
    "            new_difficulty = float(new_states[1])\n",
    "            card.iat[idx, field_map[\"stability\"]] = new_stability\n",
    "            card.iat[idx, field_map[\"difficulty\"]] = new_difficulty\n",
    "            card.iat[idx, field_map[\"states\"]] = new_states\n",
    "            card.iat[idx, field_map[\"reps\"]] = reps + 1\n",
    "            card.iat[idx, field_map[\"time\"]] += recall_time\n",
    "\n",
    "            delta_t, factor = scheduler(stability)\n",
    "            card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "            card.iat[idx, field_map[\"factor\"]] = factor\n",
    "        else:\n",
    "            review_time_today += forget_cost\n",
    "\n",
    "            rating = 1\n",
    "            card.iat[idx, field_map[\"r_history\"]] += f\",{rating}\"\n",
    "\n",
    "            new_states = student.next_states(states, ivl, 1)\n",
    "            new_stability = float(new_states[0])\n",
    "            new_difficulty = float(new_states[1])\n",
    "\n",
    "            card.iat[idx, field_map[\"stability\"]] = new_stability\n",
    "            card.iat[idx, field_map[\"difficulty\"]] = new_difficulty\n",
    "            card.iat[idx, field_map[\"states\"]] = new_states\n",
    "\n",
    "            reps = 0\n",
    "            lapses = lapses + 1\n",
    "\n",
    "            card.iat[idx, field_map[\"reps\"]] = reps\n",
    "            card.iat[idx, field_map[\"lapses\"]] = lapses\n",
    "            delta_t, factor = scheduler(stability)\n",
    "            card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "            card.iat[idx, field_map[\"factor\"]] = factor\n",
    "\n",
    "            card.iat[idx, field_map[\"time\"]] += forget_cost\n",
    "\n",
    "    need_learn = card[card[\"stability\"] == 0]\n",
    "\n",
    "    for idx in need_learn.index:\n",
    "        if (\n",
    "            learned >= new_cards_limits\n",
    "            or review_time_today + learn_time_today >= max_time_limts\n",
    "        ):\n",
    "            break\n",
    "        learned += 1\n",
    "        learn_time_today += learn_cost\n",
    "        card.iat[idx, field_map[\"last_date\"]] = day\n",
    "\n",
    "        card.iat[idx, field_map[\"reps\"]] = 1\n",
    "        card.iat[idx, field_map[\"lapses\"]] = 0\n",
    "\n",
    "        r, t, p, new_states = student.init()\n",
    "        new_stability = float(new_states[0])\n",
    "        new_difficulty = float(new_states[1])\n",
    "        card['r_history'] = card['r_history'].astype(object)\n",
    "        card['t_history'] = card['t_history'].astype(object)\n",
    "        card['p_history'] = card['p_history'].astype(object)\n",
    "        card.iat[idx, field_map[\"r_history\"]] = str(r)\n",
    "        card.iat[idx, field_map[\"t_history\"]] = str(t)\n",
    "        card.iat[idx, field_map[\"p_history\"]] = str(p)\n",
    "        card.iat[idx, field_map[\"stability\"]] = new_stability\n",
    "        card.iat[idx, field_map[\"difficulty\"]] = new_difficulty\n",
    "        card.iat[idx, field_map[\"states\"]] = new_states\n",
    "\n",
    "        delta_t, factor = scheduler(stability)\n",
    "        card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "        card.iat[idx, field_map[\"factor\"]] = factor\n",
    "\n",
    "        card.iat[idx, field_map[\"time\"]] = learn_cost\n",
    "\n",
    "\n",
    "    new_card_per_day[day] = learned\n",
    "    review_card_per_day[day] = reviewed\n",
    "    learned_per_day[day] = learned_per_day[day - 1] + learned\n",
    "    time_per_day[day] = review_time_today + learn_time_today\n",
    "    expected_memorization_per_day[day] = sum(\n",
    "        card[card[\"retrievability\"] > 0][\"retrievability\"]\n",
    "    )\n",
    "\n",
    "    if day >= moving_average_period:\n",
    "        new_card_per_day_average_per_period[day] = np.true_divide(\n",
    "            new_card_per_day[day - moving_average_period: day].sum(),\n",
    "            moving_average_period,\n",
    "        )\n",
    "        review_card_per_day_average_per_period[day] = np.true_divide(\n",
    "            review_card_per_day[day - moving_average_period: day].sum(),\n",
    "            moving_average_period,\n",
    "        )\n",
    "        time_per_day_average_per_period[day] = np.true_divide(\n",
    "            time_per_day[day - moving_average_period: day].sum(),\n",
    "            moving_average_period,\n",
    "        )\n",
    "    else:\n",
    "        new_card_per_day_average_per_period[day] = np.true_divide(\n",
    "            new_card_per_day[: day + 1].sum(), day + 1\n",
    "        )\n",
    "        review_card_per_day_average_per_period[day] = np.true_divide(\n",
    "            review_card_per_day[: day + 1].sum(), day + 1\n",
    "        )\n",
    "        time_per_day_average_per_period[day] = np.true_divide(\n",
    "            time_per_day[: day + 1].sum(), day + 1\n",
    "        )\n",
    "\n",
    "total_learned = sum(new_card_per_day)\n",
    "total_time = sum(time_per_day)\n",
    "total_remembered = int(card[\"retrievability\"].sum())\n",
    "total_leeches = len(card[card[\"lapses\"] >= leechThreshold])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>stability</th>\n",
       "      <th>retrievability</th>\n",
       "      <th>delta_t</th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>last_date</th>\n",
       "      <th>due</th>\n",
       "      <th>r_history</th>\n",
       "      <th>t_history</th>\n",
       "      <th>p_history</th>\n",
       "      <th>states</th>\n",
       "      <th>time</th>\n",
       "      <th>factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.7352</td>\n",
       "      <td>10.5114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>[tensor(10.5114), tensor(3.7352)]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.8944</td>\n",
       "      <td>1.2746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>[tensor(1.2746), tensor(6.8944)]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.3148</td>\n",
       "      <td>5.7619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.06</td>\n",
       "      <td>[tensor(5.7619), tensor(5.3148)]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8.4740</td>\n",
       "      <td>1.1008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[tensor(1.1008), tensor(8.4740)]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.7352</td>\n",
       "      <td>10.5114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>[tensor(10.5114), tensor(3.7352)]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  difficulty  stability  retrievability  delta_t  reps  lapses  \\\n",
       "0   1      3.7352    10.5114             0.0       15     1       0   \n",
       "1   2      6.8944     1.2746             NaN        0     1       0   \n",
       "2   3      5.3148     5.7619             0.0       25     1       0   \n",
       "3   4      8.4740     1.1008             0.0       23     1       0   \n",
       "4   5      3.7352    10.5114             0.0       16     1       0   \n",
       "\n",
       "   last_date  due r_history t_history p_history  \\\n",
       "0         30   36         4        29      0.32   \n",
       "1         30   36         2        29      0.36   \n",
       "2         30   36         3        29      0.06   \n",
       "3         30   36         1        29      0.25   \n",
       "4         30   36         4        29      0.32   \n",
       "\n",
       "                              states  time  factor  \n",
       "0  [tensor(10.5114), tensor(3.7352)]   0.0     2.5  \n",
       "1   [tensor(1.2746), tensor(6.8944)]   0.0     2.5  \n",
       "2   [tensor(5.7619), tensor(5.3148)]   0.0     2.5  \n",
       "3   [tensor(1.1008), tensor(8.4740)]   0.0     2.5  \n",
       "4  [tensor(10.5114), tensor(3.7352)]   0.0     2.5  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]C:\\Users\\Moses\\AppData\\Local\\Temp\\ipykernel_32436\\479842877.py:150: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  card.iat[idx, field_map[\"r_history\"]] = str(r)\n",
      "C:\\Users\\Moses\\AppData\\Local\\Temp\\ipykernel_32436\\479842877.py:151: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  card.iat[idx, field_map[\"t_history\"]] = str(t)\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.dtype' object has no attribute 'kind'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mc:\\Users\\Moses\\.vscode\\aitutor_local\\AiTutor\\part_4\\fsrs4anki_simulator.ipynb Cell 10\u001B[0m line \u001B[0;36m1\n\u001B[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Moses/.vscode/aitutor_local/AiTutor/part_4/fsrs4anki_simulator.ipynb#X11sZmlsZQ%3D%3D?line=152'>153</a>\u001B[0m card\u001B[39m.\u001B[39miat[idx, field_map[\u001B[39m\"\u001B[39m\u001B[39mstability\u001B[39m\u001B[39m\"\u001B[39m]] \u001B[39m=\u001B[39m new_stability\n\u001B[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Moses/.vscode/aitutor_local/AiTutor/part_4/fsrs4anki_simulator.ipynb#X11sZmlsZQ%3D%3D?line=153'>154</a>\u001B[0m card\u001B[39m.\u001B[39miat[idx, field_map[\u001B[39m\"\u001B[39m\u001B[39mdifficulty\u001B[39m\u001B[39m\"\u001B[39m]] \u001B[39m=\u001B[39m new_difficulty\n\u001B[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Moses/.vscode/aitutor_local/AiTutor/part_4/fsrs4anki_simulator.ipynb#X11sZmlsZQ%3D%3D?line=154'>155</a>\u001B[0m card\u001B[39m.\u001B[39;49miat[idx, field_map[\u001B[39m\"\u001B[39;49m\u001B[39mstates\u001B[39;49m\u001B[39m\"\u001B[39;49m]] \u001B[39m=\u001B[39m new_states\n\u001B[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Moses/.vscode/aitutor_local/AiTutor/part_4/fsrs4anki_simulator.ipynb#X11sZmlsZQ%3D%3D?line=156'>157</a>\u001B[0m delta_t, factor \u001B[39m=\u001B[39m scheduler(\n\u001B[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Moses/.vscode/aitutor_local/AiTutor/part_4/fsrs4anki_simulator.ipynb#X11sZmlsZQ%3D%3D?line=157'>158</a>\u001B[0m     scheduler_name, new_stability, (\u001B[39mNone\u001B[39;00m, \u001B[39mNone\u001B[39;00m, \u001B[39mNone\u001B[39;00m, r)\n\u001B[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Moses/.vscode/aitutor_local/AiTutor/part_4/fsrs4anki_simulator.ipynb#X11sZmlsZQ%3D%3D?line=158'>159</a>\u001B[0m )\n\u001B[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Moses/.vscode/aitutor_local/AiTutor/part_4/fsrs4anki_simulator.ipynb#X11sZmlsZQ%3D%3D?line=159'>160</a>\u001B[0m card\u001B[39m.\u001B[39miat[idx, field_map[\u001B[39m\"\u001B[39m\u001B[39mdue\u001B[39m\u001B[39m\"\u001B[39m]] \u001B[39m=\u001B[39m day \u001B[39m+\u001B[39m delta_t\n",
      "File \u001B[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:2455\u001B[0m, in \u001B[0;36m_ScalarAccessIndexer.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   2452\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mlen\u001B[39m(key) \u001B[39m!=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mndim:\n\u001B[0;32m   2453\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\u001B[39m\"\u001B[39m\u001B[39mNot enough indexers for scalar access (setting)!\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[1;32m-> 2455\u001B[0m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mobj\u001B[39m.\u001B[39;49m_set_value(\u001B[39m*\u001B[39;49mkey, value\u001B[39m=\u001B[39;49mvalue, takeable\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_takeable)\n",
      "File \u001B[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4339\u001B[0m, in \u001B[0;36mDataFrame._set_value\u001B[1;34m(self, index, col, value, takeable)\u001B[0m\n\u001B[0;32m   4337\u001B[0m         icol \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mcolumns\u001B[39m.\u001B[39mget_loc(col)\n\u001B[0;32m   4338\u001B[0m         iindex \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mindex\u001B[39m.\u001B[39mget_loc(index)\n\u001B[1;32m-> 4339\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_mgr\u001B[39m.\u001B[39;49mcolumn_setitem(icol, iindex, value, inplace_only\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m)\n\u001B[0;32m   4340\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_clear_item_cache()\n\u001B[0;32m   4342\u001B[0m \u001B[39mexcept\u001B[39;00m (\u001B[39mKeyError\u001B[39;00m, \u001B[39mTypeError\u001B[39;00m, \u001B[39mValueError\u001B[39;00m, LossySetitemError):\n\u001B[0;32m   4343\u001B[0m     \u001B[39m# get_loc might raise a KeyError for missing labels (falling back\u001B[39;00m\n\u001B[0;32m   4344\u001B[0m     \u001B[39m#  to (i)loc will do expansion of the index)\u001B[39;00m\n\u001B[0;32m   4345\u001B[0m     \u001B[39m# column_setitem will do validation that may raise TypeError,\u001B[39;00m\n\u001B[0;32m   4346\u001B[0m     \u001B[39m#  ValueError, or LossySetitemError\u001B[39;00m\n\u001B[0;32m   4347\u001B[0m     \u001B[39m# set using a non-recursive method & reset the cache\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1306\u001B[0m, in \u001B[0;36mBlockManager.column_setitem\u001B[1;34m(self, loc, idx, value, inplace_only)\u001B[0m\n\u001B[0;32m   1304\u001B[0m col_mgr \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39miget(loc, track_ref\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m)\n\u001B[0;32m   1305\u001B[0m \u001B[39mif\u001B[39;00m inplace_only:\n\u001B[1;32m-> 1306\u001B[0m     col_mgr\u001B[39m.\u001B[39;49msetitem_inplace(idx, value)\n\u001B[0;32m   1307\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m   1308\u001B[0m     new_mgr \u001B[39m=\u001B[39m col_mgr\u001B[39m.\u001B[39msetitem((idx,), value)\n",
      "File \u001B[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1991\u001B[0m, in \u001B[0;36mSingleBlockManager.setitem_inplace\u001B[1;34m(self, indexer, value)\u001B[0m\n\u001B[0;32m   1988\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mblocks \u001B[39m=\u001B[39m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_block\u001B[39m.\u001B[39mcopy(),)\n\u001B[0;32m   1989\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_cache\u001B[39m.\u001B[39mclear()\n\u001B[1;32m-> 1991\u001B[0m \u001B[39msuper\u001B[39;49m()\u001B[39m.\u001B[39;49msetitem_inplace(indexer, value)\n",
      "File \u001B[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\base.py:326\u001B[0m, in \u001B[0;36mSingleDataManager.setitem_inplace\u001B[1;34m(self, indexer, value)\u001B[0m\n\u001B[0;32m    322\u001B[0m \u001B[39m# EAs will do this validation in their own __setitem__ methods.\u001B[39;00m\n\u001B[0;32m    323\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39misinstance\u001B[39m(arr, np\u001B[39m.\u001B[39mndarray):\n\u001B[0;32m    324\u001B[0m     \u001B[39m# Note: checking for ndarray instead of np.dtype means we exclude\u001B[39;00m\n\u001B[0;32m    325\u001B[0m     \u001B[39m#  dt64/td64, which do their own validation.\u001B[39;00m\n\u001B[1;32m--> 326\u001B[0m     value \u001B[39m=\u001B[39m np_can_hold_element(arr\u001B[39m.\u001B[39;49mdtype, value)\n\u001B[0;32m    328\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39misinstance\u001B[39m(value, np\u001B[39m.\u001B[39mndarray) \u001B[39mand\u001B[39;00m value\u001B[39m.\u001B[39mndim \u001B[39m==\u001B[39m \u001B[39m1\u001B[39m \u001B[39mand\u001B[39;00m \u001B[39mlen\u001B[39m(value) \u001B[39m==\u001B[39m \u001B[39m1\u001B[39m:\n\u001B[0;32m    329\u001B[0m     \u001B[39m# NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\u001B[39;00m\n\u001B[0;32m    330\u001B[0m     value \u001B[39m=\u001B[39m value[\u001B[39m0\u001B[39m, \u001B[39m.\u001B[39m\u001B[39m.\u001B[39m\u001B[39m.\u001B[39m]\n",
      "File \u001B[1;32mc:\\Users\\Moses\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1814\u001B[0m, in \u001B[0;36mnp_can_hold_element\u001B[1;34m(dtype, element)\u001B[0m\n\u001B[0;32m   1810\u001B[0m     \u001B[39mraise\u001B[39;00m LossySetitemError\n\u001B[0;32m   1812\u001B[0m \u001B[39mif\u001B[39;00m tipo \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[0;32m   1813\u001B[0m     \u001B[39m# TODO: itemsize check?\u001B[39;00m\n\u001B[1;32m-> 1814\u001B[0m     \u001B[39mif\u001B[39;00m tipo\u001B[39m.\u001B[39;49mkind \u001B[39mnot\u001B[39;00m \u001B[39min\u001B[39;00m \u001B[39m\"\u001B[39m\u001B[39miuf\u001B[39m\u001B[39m\"\u001B[39m:\n\u001B[0;32m   1815\u001B[0m         \u001B[39m# Anything other than float/integer we cannot hold\u001B[39;00m\n\u001B[0;32m   1816\u001B[0m         \u001B[39mraise\u001B[39;00m LossySetitemError\n\u001B[0;32m   1817\u001B[0m     \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39misinstance\u001B[39m(tipo, np\u001B[39m.\u001B[39mdtype):\n\u001B[0;32m   1818\u001B[0m         \u001B[39m# i.e. nullable IntegerDtype or FloatingDtype;\u001B[39;00m\n\u001B[0;32m   1819\u001B[0m         \u001B[39m#  we can put this into an ndarray losslessly iff it has no NAs\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'torch.dtype' object has no attribute 'kind'"
     ]
    }
   ],
   "source": [
    "# Here feature_list doesn't have id cause we don't care which question it is for simulation\n",
    "feature_list = [\n",
    "    \"difficulty\",\n",
    "    \"stability\",\n",
    "    \"retrievability\",\n",
    "    \"delta_t\",\n",
    "    \"reps\",\n",
    "    \"lapses\",\n",
    "    \"last_date\",\n",
    "    \"due\",\n",
    "    \"r_history\",\n",
    "    \"t_history\",\n",
    "    \"p_history\",\n",
    "    \"states\",\n",
    "    \"time\",\n",
    "    \"factor\",\n",
    "]\n",
    "for scheduler_name in (\"anki\", \"fsrs\"):\n",
    "    new_card_per_day = np.array([0] * learn_days)\n",
    "    new_card_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "    review_card_per_day = np.array([0.0] * learn_days)\n",
    "    review_card_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "    time_per_day = np.array([0.0] * learn_days)\n",
    "    time_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "    learned_per_day = np.array([0.0] * learn_days)\n",
    "    retention_per_day = np.array([0.0] * learn_days)\n",
    "    expected_memorization_per_day = np.array([0.0] * learn_days)\n",
    "\n",
    "    card = pd.DataFrame(\n",
    "        np.zeros((deck_size, len(feature_list))),\n",
    "        index=range(deck_size),\n",
    "        columns=feature_list,\n",
    "    )\n",
    "    card[\"states\"] = card[\"states\"].astype(object)\n",
    "    card['reps'] = df['review_state'].apply(lambda x: len(x))\n",
    "    card[\"lapses\"] = 0\n",
    "    card[\"due\"] = learn_days\n",
    "    card[\"last_date\"] = df[\"review_time\"].apply(lambda x: x[-1])\n",
    "    \n",
    "    student = Collection()\n",
    "    random.seed(2022)\n",
    "    for day in tqdm(range(learn_days)):\n",
    "        reviewed = 0\n",
    "        learned = 0\n",
    "        review_time_today = 0\n",
    "        learn_time_today = 0\n",
    "\n",
    "        card[\"delta_t\"] = day - card[\"last_date\"]\n",
    "        card[\"retrievability\"] = np.power(\n",
    "            1 + card[\"delta_t\"] / (9 * card[\"stability\"]), -1\n",
    "        )\n",
    "        need_review = (\n",
    "            card[card[\"due\"] <= day]\n",
    "            if leechSuspend == False\n",
    "            else card[(card[\"due\"] <= day) & (card[\"lapses\"] < leechThreshold)]\n",
    "        )\n",
    "        retention_per_day[day] = need_review[\"retrievability\"].mean()\n",
    "        for idx in need_review.index:\n",
    "            if (\n",
    "                reviewed >= review_limits\n",
    "                or review_time_today + learn_time_today >= max_time_limts\n",
    "            ):\n",
    "                break\n",
    "\n",
    "            reviewed += 1\n",
    "            last_date = card.iat[idx, field_map[\"last_date\"]]\n",
    "            due = card.iat[idx, field_map[\"due\"]]\n",
    "            factor = card.iat[idx, field_map[\"factor\"]]\n",
    "            card.iat[idx, field_map[\"last_date\"]] = day\n",
    "            ivl = card.iat[idx, field_map[\"delta_t\"]]\n",
    "            card.iat[idx, field_map[\"t_history\"]] += f\",{ivl}\"\n",
    "\n",
    "            stability = card.iat[idx, field_map[\"stability\"]]\n",
    "            retrievability = card.iat[idx, field_map[\"retrievability\"]]\n",
    "            card.iat[idx, field_map[\"p_history\"]] += f\",{retrievability:.2f}\"\n",
    "            reps = card.iat[idx, field_map[\"reps\"]]\n",
    "            lapses = card.iat[idx, field_map[\"lapses\"]]\n",
    "            states = card.iat[idx, field_map[\"states\"]]\n",
    "\n",
    "            if random.random() < retrievability:\n",
    "                rating = generate_rating(\"recall\")\n",
    "                recall_time = recall_costs[rating - 2]\n",
    "                review_time_today += recall_time\n",
    "                card.iat[idx, field_map[\"r_history\"]] += f\",{rating}\"\n",
    "                new_states = student.next_states(states, ivl, rating)\n",
    "                new_stability = float(new_states[0])\n",
    "                new_difficulty = float(new_states[1])\n",
    "                card.iat[idx, field_map[\"stability\"]] = new_stability\n",
    "                card.iat[idx, field_map[\"difficulty\"]] = new_difficulty\n",
    "                card.iat[idx, field_map[\"states\"]] = new_states\n",
    "                card.iat[idx, field_map[\"reps\"]] = reps + 1\n",
    "                card.iat[idx, field_map[\"time\"]] += recall_time\n",
    "\n",
    "                delta_t, factor = scheduler(\n",
    "                    scheduler_name,\n",
    "                    new_stability,\n",
    "                    (due - last_date, ivl, factor, rating),\n",
    "                )\n",
    "                card.iat[idx, field_map[\"factor\"]] = factor\n",
    "                card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "\n",
    "            else:\n",
    "                review_time_today += forget_cost\n",
    "\n",
    "                rating = 1\n",
    "                card.iat[idx, field_map[\"r_history\"]] += f\",{rating}\"\n",
    "\n",
    "                new_states = student.next_states(states, ivl, 1)\n",
    "                new_stability = float(new_states[0])\n",
    "                new_difficulty = float(new_states[1])\n",
    "\n",
    "                card.iat[idx, field_map[\"stability\"]] = new_stability\n",
    "                card.iat[idx, field_map[\"difficulty\"]] = new_difficulty\n",
    "                card.iat[idx, field_map[\"states\"]] = new_states\n",
    "\n",
    "                reps = 0\n",
    "                lapses = lapses + 1\n",
    "\n",
    "                card.iat[idx, field_map[\"reps\"]] = reps\n",
    "                card.iat[idx, field_map[\"lapses\"]] = lapses\n",
    "\n",
    "                delta_t, factor = scheduler(\n",
    "                    scheduler_name,\n",
    "                    new_stability,\n",
    "                    (due - last_date, ivl, factor, rating),\n",
    "                )\n",
    "                card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "                card.iat[idx, field_map[\"factor\"]] = factor\n",
    "                card.iat[idx, field_map[\"time\"]] += forget_cost\n",
    "\n",
    "        need_learn = card[card[\"stability\"] == 0]\n",
    "\n",
    "        for idx in need_learn.index:\n",
    "            if (\n",
    "                learned >= new_cards_limits\n",
    "                or review_time_today + learn_time_today >= max_time_limts\n",
    "            ):\n",
    "                break\n",
    "            learned += 1\n",
    "            learn_time_today += learn_cost\n",
    "            card.iat[idx, field_map[\"last_date\"]] = day\n",
    "\n",
    "            card.iat[idx, field_map[\"reps\"]] = 1\n",
    "            card.iat[idx, field_map[\"lapses\"]] = 0\n",
    "\n",
    "            r, t, p, new_states = student.init()\n",
    "            new_stability = float(new_states[0])\n",
    "            new_difficulty = float(new_states[1])\n",
    "\n",
    "            card.iat[idx, field_map[\"r_history\"]] = str(r)\n",
    "            card.iat[idx, field_map[\"t_history\"]] = str(t)\n",
    "            card.iat[idx, field_map[\"p_history\"]] = str(p)\n",
    "            card.iat[idx, field_map[\"stability\"]] = new_stability\n",
    "            card.iat[idx, field_map[\"difficulty\"]] = new_difficulty\n",
    "            card.iat[idx, field_map[\"states\"]] = new_states\n",
    "\n",
    "            delta_t, factor = scheduler(\n",
    "                scheduler_name, new_stability, (None, None, None, r)\n",
    "            )\n",
    "            card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "            card.iat[idx, field_map[\"time\"]] = learn_cost\n",
    "            card.iat[idx, field_map[\"factor\"]] = factor\n",
    "\n",
    "        new_card_per_day[day] = learned\n",
    "        review_card_per_day[day] = reviewed\n",
    "        learned_per_day[day] = learned_per_day[day - 1] + learned\n",
    "        time_per_day[day] = review_time_today + learn_time_today\n",
    "        expected_memorization_per_day[day] = sum(\n",
    "            card[card[\"retrievability\"] > 0][\"retrievability\"]\n",
    "        )\n",
    "\n",
    "        if day >= moving_average_period:\n",
    "            new_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                new_card_per_day[day - moving_average_period: day].sum(),\n",
    "                moving_average_period,\n",
    "            )\n",
    "            review_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                review_card_per_day[day - moving_average_period: day].sum(),\n",
    "                moving_average_period,\n",
    "            )\n",
    "            time_per_day_average_per_period[day] = np.true_divide(\n",
    "                time_per_day[day - moving_average_period: day].sum(),\n",
    "                moving_average_period,\n",
    "            )\n",
    "        else:\n",
    "            new_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                new_card_per_day[: day + 1].sum(), day + 1\n",
    "            )\n",
    "            review_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                review_card_per_day[: day + 1].sum(), day + 1\n",
    "            )\n",
    "            time_per_day_average_per_period[day] = np.true_divide(\n",
    "                time_per_day[: day + 1].sum(), day + 1\n",
    "            )\n",
    "\n",
    "    total_learned = sum(new_card_per_day)\n",
    "    total_time = sum(time_per_day)\n",
    "    total_remembered = int(card[\"retrievability\"].sum())\n",
    "    total_leeches = len(card[card[\"lapses\"] >= leechThreshold])\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(review_card_per_day_average_per_period, label=f\"{scheduler_name}\")\n",
    "    plt.figure(2)\n",
    "    plt.plot(time_per_day_average_per_period / 60, label=f\"{scheduler_name}\")\n",
    "    plt.figure(3)\n",
    "    plt.plot(learned_per_day, label=f\"{scheduler_name}\")\n",
    "    plt.figure(4)\n",
    "    plt.plot(retention_per_day, label=f\"{scheduler_name}\")\n",
    "    plt.figure(5)\n",
    "    plt.plot(expected_memorization_per_day, label=f\"{scheduler_name}\")\n",
    "\n",
    "    print(\"scheduler:\", scheduler_name)\n",
    "    print(\"learned cards:\", total_learned)\n",
    "    print(\"time in minutes:\", round(total_time / 60, 1))\n",
    "    print(\"remembered cards:\", total_remembered)\n",
    "    print(\"time per remembered card:\", round(\n",
    "        total_time / 60 / total_remembered, 2))\n",
    "    print(\"leeches:\", total_leeches)\n",
    "\n",
    "    save = card[card[\"retrievability\"] > 0].copy()\n",
    "    save[\"stability\"] = round(save[\"stability\"], 2)\n",
    "    save[\"retrievability\"] = round(save[\"retrievability\"], 2)\n",
    "    save[\"difficulty\"] = round(save[\"difficulty\"], 2)\n",
    "    save[\"factor\"] = round(save[\"factor\"], 2)\n",
    "    save[\"time\"] = round(save[\"time\"], 2)\n",
    "\n",
    "    save.to_csv(f\"./simulator-{scheduler_name}.csv\", index=False, sep=\"\\t\")\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title(f\"new cards limits:{new_cards_limits}-learn days:{learn_days}\")\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(f\"review cards per day ({moving_average_period} days average)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.figure(2)\n",
    "plt.title(f\"new cards limits:{new_cards_limits}-learn days:{learn_days}\")\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(f\"time in minutes per day ({moving_average_period} days average)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.figure(3)\n",
    "plt.title(f\"new cards limits:{new_cards_limits}-learn days:{learn_days}\")\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(f\"cards total learned\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.figure(4)\n",
    "plt.title(f\"new cards limits:{new_cards_limits}-learn days:{learn_days}\")\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(\"retention per day\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.figure(5)\n",
    "plt.title(f\"new cards limits:{new_cards_limits}-learn days:{learn_days}\")\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(\"expected memorization per day\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty</th>\n",
       "      <th>stability</th>\n",
       "      <th>retrievability</th>\n",
       "      <th>delta_t</th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>last_date</th>\n",
       "      <th>due</th>\n",
       "      <th>r_history</th>\n",
       "      <th>t_history</th>\n",
       "      <th>p_history</th>\n",
       "      <th>states</th>\n",
       "      <th>time</th>\n",
       "      <th>factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.314800</td>\n",
       "      <td>28.385338</td>\n",
       "      <td>0.870514</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>67</td>\n",
       "      <td>3,3</td>\n",
       "      <td>0,11</td>\n",
       "      <td>0.53,0.82</td>\n",
       "      <td>[tensor(28.3853), tensor(5.3148)]</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.074532</td>\n",
       "      <td>50.033703</td>\n",
       "      <td>0.922180</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>110</td>\n",
       "      <td>3,4</td>\n",
       "      <td>0,11</td>\n",
       "      <td>0.53,0.82</td>\n",
       "      <td>[tensor(50.0337), tensor(4.0745)]</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.985944</td>\n",
       "      <td>5.397592</td>\n",
       "      <td>0.941836</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>2,3,1,4,1,3</td>\n",
       "      <td>0,3,14,5,18,6</td>\n",
       "      <td>0.16,0.79,0.82,0.82,0.82,0.82</td>\n",
       "      <td>[tensor(5.3976), tensor(9.9859)]</td>\n",
       "      <td>0.014</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.205385</td>\n",
       "      <td>44.429798</td>\n",
       "      <td>0.954640</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>118</td>\n",
       "      <td>1,3,3,4</td>\n",
       "      <td>0,2,7,21</td>\n",
       "      <td>0.11,0.83,0.82,0.82</td>\n",
       "      <td>[tensor(44.4298), tensor(7.2054)]</td>\n",
       "      <td>0.014</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.499671</td>\n",
       "      <td>107.331604</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>233</td>\n",
       "      <td>4,4</td>\n",
       "      <td>0,21</td>\n",
       "      <td>0.21,0.82</td>\n",
       "      <td>[tensor(107.3316), tensor(2.4997)]</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   difficulty   stability  retrievability  delta_t  reps  lapses  last_date  \\\n",
       "0    5.314800   28.385338        0.870514       38     2       0         11   \n",
       "1    4.074532   50.033703        0.922180       38     2       0         11   \n",
       "2    9.985944    5.397592        0.941836        3     1       2         46   \n",
       "3    7.205385   44.429798        0.954640       19     4       0         30   \n",
       "4    2.499671  107.331604        0.971831       28     2       0         21   \n",
       "\n",
       "   due    r_history      t_history                      p_history  \\\n",
       "0   67          3,3           0,11                      0.53,0.82   \n",
       "1  110          3,4           0,11                      0.53,0.82   \n",
       "2   57  2,3,1,4,1,3  0,3,14,5,18,6  0.16,0.79,0.82,0.82,0.82,0.82   \n",
       "3  118      1,3,3,4       0,2,7,21            0.11,0.83,0.82,0.82   \n",
       "4  233          4,4           0,21                      0.21,0.82   \n",
       "\n",
       "                               states   time  factor  \n",
       "0   [tensor(28.3853), tensor(5.3148)]  0.005     2.5  \n",
       "1   [tensor(50.0337), tensor(4.0745)]  0.004     2.5  \n",
       "2    [tensor(5.3976), tensor(9.9859)]  0.014     2.5  \n",
       "3   [tensor(44.4298), tensor(7.2054)]  0.014     2.5  \n",
       "4  [tensor(107.3316), tensor(2.4997)]  0.004     2.5  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOm4HfyD2iOIc2PUtxA92by",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fsrs4anki')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8dd9a290ffd10997e0b0d411ff1325a47862ea932e0fd309ade800e0e51d2b4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}